DATA:
  DATASET_DIR: /mnt/DATA1/Sagi/Data/  # Full path to dataset parent directory
  DATASETS: BraTS2020 # Name of dataset directory
  DATA_SPLIT_FILE: datasets/data_splits/brats20/train_val_test_split.json # Path to dataset split file. Files located at: datasets/data_splits
  PREPROCESS:
    RESIZE_MODE: 'interpolate'  # Options: 'interpolate' or 'padding'. Resize method
    SCAN_NORM_MODE: 'slice'   # Options: 'slice', 'scan', None. Minmax normalization option (for 'slice' normalization is applied separately for each slice, for 'scan' it is applied on the entire scan at once)

TRAINING:
  OUTPUT_DIR: /mnt/DATA1/Sagi/Models/LGMViT/  # Path to parent directory where the experiments (checkpoints) will be saved to
  INPUT_SIZE: 256   # Spatial input size (H and W)
  LR: 0.00001   # Initial learning rate
  SCAN_SEG_SIZE: 32   # Number of slices for each forward pass. This number must be a factor of the batch size. Reduce this number in cases where the desired batch size exceeds the GPU memory.
  BATCH_SIZE: 32    # Effective batch size
  MAX_SCAN_SIZE: null   # The maximum size (number of slices) of a scan that is acceptable. For scans with more slices than this number, a random continuous seg the size of this number will be selected (cropped). Set None for no size limit.
  WEIGHT_DECAY: 0.0001    # Weight decay parameter
  EPOCHS: 25    # Number of epochs to train
  CLIP_MAX_NORM: 0    # Clip gradients
  EVAL_INTERVAL: 1    # Interval length (in epochs) for evaluation on validation set
  SAVE_CKPT_INTERVAL: 1   # Interval length (in epochs) to save checkpoints
  SAVE_BEST_CKPT_CRITERION: 'f1'    # Options: 'f1', 'acc', 'auroc', 'auprc', 'cohen_kappa'. Criterion in which to save checkpoint for best epoch.
  RESUME: ''    # Resume from checkpoint. Options: 'latest' (resumes from the last saved epoch), insert full path to checkpoint, insert url to checkpoint
  START_EPOCH: 1    # Initialize the epoch count of training session
  EVAL: false
  NUM_WORKERS: 4
  CLS_THRESH: 0.5   # Binary classification threshold for evaluation of the model's prediction
  LOSS:
    TYPE: 'bce' # Classification loss type (currently only supports binary cross entropy)
    LOCALIZATION_LOSS:
      USE: false    # Apply localization loss

MODEL:
  PRETRAINED_WEIGHTS:   # Path to pretrained weights
  NUM_CLASSES: 2    # Number of classes for classification (currently only supports 2 - binary classification)
  PATCH_SIZE: 16    # Patch size for patch embedding module
  POSITION_EMBEDDING:
    TYPE: sine    # Options: 'sine', 'learned', null. Type of positional encoding
  VIT_ENCODER:
    NUM_LAYERS: 12    # Number of ViT encoder blocks
    FORWARD_EXPANSION_RATIO: 4    # MLP expansion parameter in ViT block
    EMBED_SIZE: 768   # Embedding size
    HEADS: 12   # Number of heads
    DROP_PATH: 0.1    # Drop path ratio (ViT Block)
    FORWARD_DROP_P: 0.1   # Drop path ratio (MLP inside the ViT Block)
    USE_CLS_TOKEN: true   # Use class token (currently mandatory)
    ATTENTION_3D: false   # Apply 3D attention instead of 2D

TEST:
  CHECKPOINT: 'best'    # Checkpoint to load. Options: 'best' (loads the best epoch saved during training), number of type int (loads a specific checkpoint by number), or insert full path to checkpoint(.pth).
  CHECKPOINT_PARENT_DIR: null   # Path to parent directory where the checkpoint are saved (relevant for 'best' and int options of cfg.TEST.CHECKPOINT). Default (or None) is set to cfg.TRAINING.OUTPUT_DIR where the training checkpoints of this config are saved.
  CLS_THRESH: 0.5   # Binary classification threshold for evaluation of the model's prediction
  NUM_WORKERS: 4

DISTRIBUTED:
  WORLD_SIZE: 1
  DIST_URL: env://
